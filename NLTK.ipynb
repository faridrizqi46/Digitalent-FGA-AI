{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9vOa8eCA3x0",
        "outputId": "6e7fbb18-9bc6-4cb1-d867-43cdf64671aa"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "from nltk import tokenize\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBCpor1dDW7z"
      },
      "source": [
        "raw_txt = \"\"\"Welcome to the world of Deep Learning for NLP!\\\n",
        "             We're in this together, and we'll learn together.\\\n",
        "             NLP is amazing,\\\n",
        "             and Deep Learning makes it even more fun.\\\n",
        "             Let's learn!\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4045gesND5zS",
        "outputId": "045da312-033a-4c23-c106-a7bfae0f4896"
      },
      "source": [
        "print(raw_txt)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to the world of Deep Learning for NLP!             We're in this together, and we'll learn together.             NLP is amazing,             and Deep Learning makes it even more fun.             Let's learn!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phEJrbwjDhmK",
        "outputId": "ed2cfbdd-445d-47b3-b8c1-624cc0c953a4"
      },
      "source": [
        "txt_sents = tokenize.sent_tokenize(raw_txt)\n",
        "print(txt_sents)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Welcome to the world of Deep Learning for NLP!', \"We're in this together, and we'll learn together.\", 'NLP is amazing,             and Deep Learning makes it even more fun.', \"Let's learn!\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puGLze-dD8eC",
        "outputId": "e21d5465-9d7a-4c2d-d4d5-5f7d3d0ba1fc"
      },
      "source": [
        "print(type(txt_sents))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ2mDCz-ET35",
        "outputId": "74dc1298-7bc1-4a34-cfd4-514e7f3d133a"
      },
      "source": [
        "print(len(txt_sents))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcjxVToKEsjq",
        "outputId": "587c1b23-ddba-4c4a-cfd7-2ab65dba2c35"
      },
      "source": [
        "for i in range(len(txt_sents)):\n",
        "  print(txt_sents[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to the world of Deep Learning for NLP!\n",
            "We're in this together, and we'll learn together.\n",
            "NLP is amazing,             and Deep Learning makes it even more fun.\n",
            "Let's learn!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxWtt7RCFi6C",
        "outputId": "be4f2055-229c-4b7e-cc18-f6724cc777ca"
      },
      "source": [
        "txt_word_sentence1 = tokenize.word_tokenize(txt_sents[0])\n",
        "print(len(txt_word_sentence1))\n",
        "print(txt_word_sentence1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "['Welcome', 'to', 'the', 'world', 'of', 'Deep', 'Learning', 'for', 'NLP', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9JhOsG3GbVQ",
        "outputId": "f6d55afb-5a5c-4a90-802f-bc1f4a302b03"
      },
      "source": [
        "txt_words = [tokenize.word_tokenize(i) for i in txt_sents]\n",
        "print(txt_words)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Welcome', 'to', 'the', 'world', 'of', 'Deep', 'Learning', 'for', 'NLP', '!'], ['We', \"'re\", 'in', 'this', 'together', ',', 'and', 'we', \"'ll\", 'learn', 'together', '.'], ['NLP', 'is', 'amazing', ',', 'and', 'Deep', 'Learning', 'makes', 'it', 'even', 'more', 'fun', '.'], ['Let', \"'s\", 'learn', '!']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q31fZeOLGpEB",
        "outputId": "76f0e085-68c8-4ee2-c775-4f2687271385"
      },
      "source": [
        "raw_txt_lower = raw_txt.lower()\n",
        "print(raw_txt_lower)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "welcome to the world of deep learning for nlp!             we're in this together, and we'll learn together.             nlp is amazing,             and deep learning makes it even more fun.             let's learn!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO2lHcyTG-EZ",
        "outputId": "8e569283-1676-4ba5-fd8e-2e597c2d0466"
      },
      "source": [
        "print(type(raw_txt))\n",
        "txt_sents_lower = [sent.lower() for sent in txt_sents]\n",
        "print(txt_sents_lower)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "['welcome to the world of deep learning for nlp!', \"we're in this together, and we'll learn together.\", 'nlp is amazing,             and deep learning makes it even more fun.', \"let's learn!\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dky11tFyIS2a",
        "outputId": "17ece4ae-7898-4131-a1f0-8fae2210573f"
      },
      "source": [
        "list_punct = list(punctuation)\n",
        "print(list_punct)\n",
        "print(len(list_punct))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjn7S1XyK9v4"
      },
      "source": [
        "txt_words_lower = [tokenize.word_tokenize(i) for i in txt_sents_lower]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOm119RnKlZI"
      },
      "source": [
        "def drop_punct(x):\n",
        "  drop = [i for i in x if i not in list_punct]\n",
        "  return drop"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RziDt8vmIk8o",
        "outputId": "191bfb9e-11d5-4815-8266-74c621eb94f5"
      },
      "source": [
        "txt_words_nopunct = [drop_punct(i) for i in txt_words]\n",
        "print(txt_words_nopunct)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Welcome', 'to', 'the', 'world', 'of', 'Deep', 'Learning', 'for', 'NLP'], ['We', \"'re\", 'in', 'this', 'together', 'and', 'we', \"'ll\", 'learn', 'together'], ['NLP', 'is', 'amazing', 'and', 'Deep', 'Learning', 'makes', 'it', 'even', 'more', 'fun'], ['Let', \"'s\", 'learn']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7feVIZFeKGOn",
        "outputId": "dded16f1-2062-4e0a-a154-d0913c7ef10a"
      },
      "source": [
        "list_stop = stopwords.words('english')\n",
        "print(list_stop)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o94-dIY2LiYP",
        "outputId": "70bccc1c-2e0a-4cc2-879f-81c0bcaef448"
      },
      "source": [
        "list_final = list_punct + list_stop\n",
        "print(list_final)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFqon8HoLtk_"
      },
      "source": [
        "def drop_punct_stop(x):\n",
        "  drop = [i for i in x if i not in list_final]\n",
        "  return drop"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yG5C9DMMRVi",
        "outputId": "31ab86cf-af4c-4a86-9df5-c80c2f0f120e"
      },
      "source": [
        "txt_final = [drop_punct_stop(i) for i in txt_words_lower]\n",
        "print(txt_final)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['welcome', 'world', 'deep', 'learning', 'nlp'], [\"'re\", 'together', \"'ll\", 'learn', 'together'], ['nlp', 'amazing', 'deep', 'learning', 'makes', 'even', 'fun'], ['let', \"'s\", 'learn']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH1N6T3dMpOv",
        "outputId": "178b622e-d061-4cd6-c14e-19cd07a4b646"
      },
      "source": [
        "stemer_p = PorterStemmer()\n",
        "stem1 = stemer_p.stem('Driving')\n",
        "print(stem1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zObDw7HNqn-",
        "outputId": "a95b9b5a-9b3f-4525-f9d0-39dc591af26e"
      },
      "source": [
        "stem2 = stemer_p.stem(txt_sents[0])\n",
        "print(stem2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "welcome to the world of deep learning for nlp!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jBKogfOOCae"
      },
      "source": [
        "txt_words = [tokenize.word_tokenize(sent) for sent in txt_sents]\n",
        "txt = '''I mustered all my drive,\\ \n",
        "\t   drove to the driving school!'''\n",
        "tokens = tokenize.word_tokenize(txt)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlrW_HHMOVAY",
        "outputId": "8330a308-bfa3-4afa-cb50-3f4d5fc0834e"
      },
      "source": [
        "print([stemer_p.stem(word) for word in tokens])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'muster', 'all', 'my', 'drive', ',', '\\\\', 'drove', 'to', 'the', 'drive', 'school', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQsOTRRdOnP-"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uavQYzZjPMzJ"
      },
      "source": [
        "lem_test = lemmatizer.lemmatize(\"ponies\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sijCChqUPSz9",
        "outputId": "59e6845d-c6d0-41c7-bb69-10403f1e66e2"
      },
      "source": [
        "print(lem_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pony\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ec1z_OMPUwj",
        "outputId": "b335aea0-c3eb-4f79-e4af-85426645beb2"
      },
      "source": [
        "lem_test2 = lemmatizer.lemmatize(\"mice\")\n",
        "print(lem_test2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mouse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qrmD11APiK1",
        "outputId": "f352eebc-1784-4d97-e4a5-22b783a8b23b"
      },
      "source": [
        "lem_test3 = lemmatizer.lemmatize(\"geese\")\n",
        "print(lem_test3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "goose\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9bNAYETPpIF",
        "outputId": "f1f80fce-9e7a-49a8-9b7d-3ca5cfec6cd7"
      },
      "source": [
        "stem3 = stemer_p.stem('Mice')\n",
        "print(stem3)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-2xWUL8P0au",
        "outputId": "54128865-b529-4780-d833-5bc0ebbd4487"
      },
      "source": [
        "#txt_final\n",
        "target_terms = ['nlp', 'deep', 'learn']\n",
        "\n",
        "def get_onehot(x):\n",
        "  y = [1 if i in x else 0 for i in target_terms]\n",
        "  return y\n",
        "\n",
        "one_hot_matrix = [get_onehot(i) for i in txt_final]\n",
        "print(txt_final)\n",
        "print(np.array(one_hot_matrix))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['welcome', 'world', 'deep', 'learning', 'nlp'], [\"'re\", 'together', \"'ll\", 'learn', 'together'], ['nlp', 'amazing', 'deep', 'learning', 'makes', 'even', 'fun'], ['let', \"'s\", 'learn']]\n",
            "[[1 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XouXjpXuRxvN",
        "outputId": "9f6d9116-f4e4-48d9-d329-51a4b9795620"
      },
      "source": [
        "vectorizer = CountVectorizer(max_features = 5)\n",
        "vectorizer.fit(txt_sents)\n",
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'deep': 1, 'we': 4, 'together': 3, 'and': 0, 'learn': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Vb6ytCTlev",
        "outputId": "7901a9a8-2515-4f07-8d70-3187c4a1df20"
      },
      "source": [
        "txt_dtm = vectorizer.fit_transform(txt_sents)\n",
        "print(txt_dtm.toarray())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0]\n",
            " [1 0 1 2 2]\n",
            " [1 1 0 0 0]\n",
            " [0 0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXxx7vvkUEoP",
        "outputId": "b40b6503-0c10-4c78-b52f-be8cd1ef802b"
      },
      "source": [
        "vectorizer_tfidf = TfidfVectorizer(max_features=5)\n",
        "vectorizer_tfidf.fit(txt_sents)\n",
        "print(vectorizer_tfidf.vocabulary_)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'deep': 1, 'we': 4, 'together': 3, 'and': 0, 'learn': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ndz2NYU_gL",
        "outputId": "48e680fa-a6c9-4fdd-ca4a-47159dcc29a7"
      },
      "source": [
        "txt_tfidf = vectorizer_tfidf.transform(txt_sents)\n",
        "print(txt_tfidf.toarray())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         1.         0.         0.         0.        ]\n",
            " [0.25932364 0.         0.25932364 0.65783832 0.65783832]\n",
            " [0.70710678 0.70710678 0.         0.         0.        ]\n",
            " [0.         0.         1.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGruG_2zVLQM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}